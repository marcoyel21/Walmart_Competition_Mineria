---
title: "Exploratorio_Walmart"
author: "Equipo 3"
date: "11/28/2020"
output: html_document
---


## Cargar funciones de UTILS 


```{r}
source("Utils.R"     , encoding = 'UTF-8')
source("00-load.R"   , encoding = 'UTF-8')
source("01-prepare.R", encoding = 'UTF-8')
source("02-clean.R"  , encoding = 'UTF-8')
```

## Exploratorio Walmart

```{r}
#Cargamos paquetes 
library(tidyverse)
library(readr)
library(ggthemes)
library("VIM")
```


## Cargamos los datos 

```{r setup }
# ya está arriba, en load.R
#walmart<-load_train()
```



```{r cars}
glimpse(walmart)
```


Información sobre las columnas:

Data fields
TripType - a categorical id representing the type of shopping trip the customer made. This is the ground truth that you are predicting. TripType_999 is an "other" category.
VisitNumber - an id corresponding to a single trip by a single customer
Weekday - the weekday of the trip
Upc - the UPC number of the product purchased
ScanCount - the number of the given item that was purchased. A negative value indicates a product return.
DepartmentDescription - a high-level description of the item's department
FinelineNumber - a more refined category for each of the products, created by Walmart



```{r pressure }
 head(walmart)
```
 
 El primer paso siempre es conocer el número de variables con las que se está trabajando y la cantidad de observaciones que se tienen.
```{r}
dim(walmart)
```
Entonces se tienen 647 054 observaciones de 7 variables.
 
Analicemos primero cuales observaciones tienen valores faltantes:
```{r}
summary(walmart)
```

```{r}
# walmart[rowSums(is.na(walmart)) > 0,]
rows_with_NAs(walmart)
```
 y vemos que de las 647 054 observaciones, 4 129 tienen valores faltantes y todas las observaciones con valores faltantes presentan estos faltantes en las columnas UPC y FinelineNumber simultáneamente.
 
```{r}
#aggr(walmart, prop=TRUE, numbers=TRUE, bars=FALSE)
prop_missings(walmart)
```
 Y observamos que el porcentaje de observaciones con valores faltantes es de 0.064% de las observaciones

Analicemos ahora cuántos valores únicos existen para cada una de las variables.

```{r}
unique_per_col(walmart)
```

Y vemos que para tener más de 600 mil observaciones, hay variables que tienen muy pocos valores únicos por lo que algunas de ellas deben de ser variables categóricas.

Observando más detenidamente el dataframe notamos que hay algunos valores en la columna de DepartmentDescription que tienen "NULL" como valor. Puede que esto se trate de un error que se dio al cambiar los datos de formato. Veamos cuantas observaciones presentan este problema:

```{r}
#filter(walmart, walmart$DepartmentDescription == 'NULL')
rows_with_string(walmart, walmart$DepartmentDescription, 'NULL')
```
Y parece que todas las observaciones con "NULL" en la columna de DepartmentDescription pertenecen al conjunto de observaciones que vimos donde tanto UPC como FinelineNumber son nulas.

Por otra parte, es obvio que hay variables que se leeyeron como un tipo cuando en realidad son otro, por ejemplo los días de la semana que se guardaron como caracter pero en realidad son categóricas, entre otrod.

Finalmente, los nombres de las columnas están bien pero por convención es mejor tenerlos en minúsculas y separados por un guión bajo '_'. 

Estos tres problemas enteriores se resolveran con la limpieza.

## Limpieza

Primero, pasamos a snake_case los nombres de las columnas y se los asignamos a su variable correspondiente.

```{r}
walmart_clean_colnames <- clean_colnames(walmart_colnames)
colnames(walmart) <- walmart_clean_colnames
```

```{r}
head(walmart)
```

Ahora, transformemos los "NULL" de la columna de department_description a NA.
```{r}
walmart$department_description <- replace_NULLs(walmart$department_description)
```

y la proporcion de valores faltantes resulta ahora:
```{r}
prop_missings(walmart)
```

Finalmente, asignemos el tipo de variable correcto a cada una de las columnas.
```{r}
walmart <- data_type_conv(walmart)
```

Checamos que se asignaron correctamente los ipos de datos:
```{r}
glimpse(walmart)
```

 
## Analisis univariado (pendiente)
 
 
## Análisis Bivariado


 Correlación de las columnas con la variable de salida: 
 
 Empezamos haciendo un análisis de correlación entre las variables numéricas.
En particular, nos interesa destacar las variables que tienen una alta correlacion positiva o negativa, con la variable price, que es la variable a predecir. 
 
 
#Analizamos corelaciciones entre variables numéricas
#No Encontramos una fuerte correlación entre ninguna variable.
 
```{r}

#Las variables numericas
walmart_numeric<-walmart %>% select(where(is.numeric))

## Correlacion entre variables numericas 
cor_matrix<-round(cor(walmart_numeric, use="complete.obs" ),2)

melted_walmart <- melt(cor_matrix)

heat_cor_numeric_walmart<-ggplot(data = melted_walmart, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()+
  theme(axis.text.x = element_text(angle=90))

heat_cor_numeric_walmart

```


#Realizamos un análisis entre variables categóricas, en prticular entre trip_type, nuestra variable a predecir, y las otras variables categóricas. 
#Observamos una gran dificultad para visualizar, dado que hay muchos trip_types. 
```{r}

# stacked bar chart

ggplot(walmart, aes(x =trip_type   , fill =  weekday)) + 
  geom_bar(position = "stack")

```



```{r}

ggplot(walmart, aes(x = scan_count    , fill =trip_type  )) + 
  geom_bar(position = "stack")+
  xlim(-5, 10)

```


```{r}

ggplot(walmart, aes(x = department_description, fill =trip_type  )) + 
  geom_bar(position = "stack")


```



#Se adjunta shinny app que contiene gráficos bivariados de variables numéricas y categóricas y de variables numéricas.


```{r}

include_graphics('imagenes/trip_type_visit_number.png')
```

Abajo observamos una relación entre tipo de viaje y finleine_number. 
Esta variación es esperable dado que suponemos que habrá una relación entre el tipo de viaje y comprar productos de una categoría en particular. 
```{r}

include_graphics('imagenes/trip_type_fineline_number.png')

##
```



